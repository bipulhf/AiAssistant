import { ConversationalRetrievalQAChain } from "langchain/chains";
import { getVectorStore } from "./vector-store";
import { getPineconeClient } from "./pinecone-client";
import {
    StreamingTextResponse,
    experimental_StreamData,
    LangChainStream,
} from "ai-stream-experimental";
import { streamingModel, nonStreamingModel } from "./llm";
import { STANDALONE_QUESTION_TEMPLATE, QA_TEMPLATE } from "./prompt-templates";

type callChainArgs = {
    question: string;
    chatHistory: string;
};

export async function callChain({ question, chatHistory }: callChainArgs) {
    try {
        // Open AI recommendation
        const sanitizedQuestion = question.trim().replaceAll("\n", " ");
        const pineconeClient = await getPineconeClient();
        const vectorStore = await getVectorStore(pineconeClient);
        const { stream, handlers } = LangChainStream({
            experimental_streamData: true,
        });
        const data = new experimental_StreamData();

        const chain = ConversationalRetrievalQAChain.fromLLM(
            streamingModel,
            vectorStore.asRetriever(),
            {
                qaTemplate: QA_TEMPLATE,
                questionGeneratorTemplate: STANDALONE_QUESTION_TEMPLATE,
                returnSourceDocuments: true, //default 4
                questionGeneratorChainOptions: {
                    llm: nonStreamingModel,
                },
            }
        );

        chain
            .call(
                {
                    question: sanitizedQuestion,
                    chat_history: chatHistory,
                },
                [handlers]
            )
            .then(async (res) => {
                const sourceDocuments = res?.sourceDocuments;
                const firstTwoDocuments = sourceDocuments.slice(0, 2);
                const pageContents = firstTwoDocuments.map(
                    ({ pageContent }: { pageContent: string }) => pageContent
                );
                console.log("already appended ", data);
                data.append({
                    sources: pageContents,
                });
                data.close();
            });

        // Return the readable stream
        return new StreamingTextResponse(stream, {}, data);
    } catch (e) {
        console.error(e);
        throw new Error("Call chain method failed to execute successfully!!");
    }
}
